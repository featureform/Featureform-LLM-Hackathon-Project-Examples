{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7046ab5",
      "metadata": {
        "id": "c7046ab5"
      },
      "source": [
        "# Quickstart (Localmode with Pinecone and Weaviate)\n",
        "\n",
        "## Requirements\n",
        "\n",
        "* Python 3.7+\n",
        "* `.env` file with one or both sets of credentials (visit [Pinecone](https://www.pinecone.io/) and/or [Weaviate](https://weaviate.io/) for instructions on creating an account and getting credentials):\n",
        "```\n",
        "# Pinecone\n",
        "\n",
        "  PINECONE_PROJECT_ID=\n",
        "PINECONE_ENVIRONMENT=\n",
        "PINECONE_API_KEY=\n",
        "HUGGING_FACE_TOKEN=\n",
        "\n",
        "# Weaviate\n",
        "\n",
        "  WEAVIATE_URL=\n",
        "WEAVIATE_API_KEY=\n",
        "```\n",
        "* [Topic Labeled News Dataset](https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset)\n",
        "* Featureform installed:\n",
        "```shell\n",
        "pip install featureform\n",
        "```\n",
        "* Hugging Face [`sentence-transformers`](https://huggingface.co/sentence-transformers) installed:\n",
        "```\n",
        "pip install sentence-transformers\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb61a5e2",
      "metadata": {
        "id": "fb61a5e2"
      },
      "source": [
        "## Step  1. Register Provider and Source\n",
        "\n",
        "We'll be using Pinecone for this example, but you can also choose to use Weaviate.\n",
        "\n",
        "**NOTE:**\n",
        "Until `sep=\";\"` is a supported parameter in `register_file`,\n",
        "you'll need to preproces the dataset by doing the following:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"labelled_newscatcher_dataset.csv\", sep=\";\")\n",
        "df.to_csv(\"newscatcher_dataset.csv\", index=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1ca4f68",
      "metadata": {
        "id": "b1ca4f68"
      },
      "outputs": [],
      "source": [
        "import featureform as ff\n",
        "from featureform import local\n",
        "import dotenv\n",
        "import os\n",
        "\n",
        "dotenv.load_dotenv(\".env\")\n",
        "\n",
        "pinecone = ff.register_pinecone(\n",
        "    name=\"pinecone4\",\n",
        "    project_id=os.getenv(\"PINECONE_PROJECT_ID\", \"\"),\n",
        "    environment=os.getenv(\"PINECONE_ENVIRONMENT\", \"\"),\n",
        "    api_key=os.getenv(\"PINECONE_API_KEY\", \"\"),\n",
        ")\n",
        "\n",
        "news = local.register_file(\n",
        "    name=\"news\",\n",
        "    description=\"108,774 news articles labelled with 8 topics (balanced)\",\n",
        "    path=\"ucb-hackathon/newscatcher_dataset.csv\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58895602",
      "metadata": {
        "id": "58895602"
      },
      "source": [
        "Now we'll create an instance of the Featureform client and apply the changes. We'll be using `client` after each step to apply our changes and checkpoint our work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d9732b4",
      "metadata": {
        "id": "2d9732b4"
      },
      "outputs": [],
      "source": [
        "from featureform import Client\n",
        "\n",
        "client = Client(local=True)\n",
        "\n",
        "client.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a5eb56",
      "metadata": {
        "id": "a1a5eb56"
      },
      "outputs": [],
      "source": [
        "!featureform list sources --local"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "748d0b8f",
      "metadata": {
        "id": "748d0b8f"
      },
      "source": [
        "## Step 2. Register Transformation\n",
        "\n",
        "Given the size of the Newscatcher dataset, we'll limit the context we'll create embeddings for to only science-related articles. Once we've filtered by the topic, we'll use [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) to create embeddings of the article titles so we can perform searches on them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2291505",
      "metadata": {
        "id": "a2291505"
      },
      "outputs": [],
      "source": [
        "@local.df_transformation(inputs=[news])\n",
        "def vectorize_science_news(news_df):\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    science_news = news_df[news_df[\"topic\"] == \"SCIENCE\"]\n",
        "\n",
        "    embeddings = model.encode(science_news[\"title\"].tolist())\n",
        "\n",
        "    science_news[\"title_embedding\"] = embeddings.tolist()\n",
        "\n",
        "    print(science_news)\n",
        "\n",
        "    return science_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47af2bd7",
      "metadata": {
        "id": "47af2bd7"
      },
      "outputs": [],
      "source": [
        "client.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482ba89e",
      "metadata": {
        "id": "482ba89e"
      },
      "source": [
        "## Step 3. Register Entity and Feature\n",
        "\n",
        "We'll now register an entity and a feature, which will kick off the materialization process.\n",
        "\n",
        "**NOTE:**\n",
        "This may take some time to complete. See the progress bar for status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8705af8f",
      "metadata": {
        "id": "8705af8f"
      },
      "outputs": [],
      "source": [
        "@ff.entity\n",
        "class NewsDomain:\n",
        "    science_news = ff.Embedding(\n",
        "        vectorize_science_news[[\"link\", \"title_embedding\"]],\n",
        "        dims=384,\n",
        "        vector_db=pinecone,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b72cd90",
      "metadata": {
        "id": "5b72cd90"
      },
      "outputs": [],
      "source": [
        "client.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8f593aa",
      "metadata": {
        "id": "c8f593aa"
      },
      "source": [
        "## Step 4. Register On-Demand Feature\n",
        "\n",
        "We'll want to query the embeddings we created, and we can do so using Featureform's on-demand feature decorator. This creates a feature that's calculated on the client at serving time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db430da3",
      "metadata": {
        "id": "db430da3"
      },
      "outputs": [],
      "source": [
        "@ff.ondemand_feature(name=\"science_news_search\")\n",
        "def search_science_news(serving_client, params, entity):\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    search_vector = model.encode(params[0])\n",
        "    feature, variant = params[1]\n",
        "\n",
        "    return serving_client.nearest(feature, variant, search_vector.tolist(), k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba26f7ca",
      "metadata": {
        "id": "ba26f7ca"
      },
      "outputs": [],
      "source": [
        "client.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb0c54f0",
      "metadata": {
        "id": "eb0c54f0"
      },
      "source": [
        "## Step 5. Serve On-Demand Feature (i.e. Semantic Search)\n",
        "\n",
        "Now we'll query the vector database via our on-demand feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8e3273",
      "metadata": {
        "id": "cd8e3273"
      },
      "outputs": [],
      "source": [
        "query = \"asteroids over England\"\n",
        "embedding_feature_variant = (\"science_news\", \"quizzical_goldstine\")\n",
        "ondemand_feature_variant = (\"science_news_search\", \"quizzical_goldstine\")\n",
        "\n",
        "features = client.features(\n",
        "    [(ondemand_feature_variant)],\n",
        "    {\"link\": \"\"},\n",
        "    params=[query, embedding_feature_variant],\n",
        ")\n",
        "\n",
        "df = features[0]\n",
        "results = \"\\n\".join(\n",
        "    [\n",
        "        url\n",
        "        for url in df[\n",
        "            f\"{ondemand_feature_variant[0]}.{ondemand_feature_variant[1]}\"\n",
        "        ].values[0]\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"SEARCH RESULTS:\\n{results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374e8b3a",
      "metadata": {
        "id": "374e8b3a"
      },
      "outputs": [],
      "source": [
        "client.apply()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}