Number;Speaker;Start time;End time;Duration;Text
0;Simba Khadder;00:00:06.140;00:00:32.030;00:00:25.890;"Hey, everyone. Simba Khadder here with the MLOps Weekly Podcast. Today I have the pleasure of speaking with Josh Wills. Josh is an investor and advisor who specializes in data and machine learning infrastructure. He was formerly Head of Data Engineering at Slack, the Director of Data Science at Cloudera, and a software engineer at Google. He also is famous for his hot takes on Twitter. Josh, great to have you here today."
1;Josh Wills;00:00:32.030;00:00:33.290;00:00:01.260;"Simba, thank you so much for having me."
2;Simba Khadder;00:00:34.080;00:00:50.620;00:00:16.540;"I just gave a quick introduction on you, but I would love to start by... You've worked across Google, you've worked at Slack, you've worked at Cloudera, you've done a lot of stuff in your career. I would love to learn about maybe some of the hardest data problems you faced or had to solve of your career."
3;Josh Wills;00:00:50.620;00:00:53.790;00:00:03.170;"Oh, man. Hardest data problems I've had to solve. That's a-"
4;Simba Khadder;00:00:54.180;00:00:57.980;00:00:03.800;"Or some interesting one you think that people would enjoy."
5;Josh Wills;00:00:58.080;00:01:28.280;00:00:30.200;"That's a tough one. I don't know. I've talked about a few of them before. I think the hardest data engineering challenge I ever had was rebuilding Slack's search indexing pipeline, which I talked about a little bit here and there before and stuff. I feel like as I reflect back on my career, that was still the Mount Everest problem for me. Or it's something even harder, maybe K2, an even technically more difficult mountain climb is a better analogy."
6;Josh Wills;00:01:28.800;00:02:06.720;00:00:37.920;"Just because of the scale of the problem, hundreds and hundreds of terabytes, it's got to be up on the order of petabytes of data to index right now. When you're dealing with data sets that large, you encounter literally every single thing that can possibly go wrong. And it's stuff that is things that are one in a trillion things happen to you because you're processing a trillion records. Every single thing that can go wrong goes wrong. I guess in terms of the technical challenge, in terms of the impact, in terms of improving the performance of Slack search and stuff like that, it's still, I think, the most meaningful problem to me. But I think that's from a technical challenge perspective."
7;Josh Wills;00:02:07.300;00:02:16.570;00:00:09.270;"From a people challenge perspective, which I think is... If you talk to most people who've done this stuff for a while, they would say the people problems are far more persistent and far more difficult and stuff like that."
8;Josh Wills;00:02:17.110;00:02:59.450;00:00:42.340;"The thing I'm proudest of is introducing at Slack, very early on in my tenure there, so right when I joined back in October of 2015, the very first thing I did was introducing the notion of I think what people call now a data contract that tied our production, web application systems and the data that they generated to send to our data warehouse and using thrift schemas and locking that stuff down really early. It's one of those things that it prevents so many problems down the line and so many challenges. Getting that done is maybe something that organizationally speaking, I'm proudest off, I think. Yeah, I don't know. What else would you like to talk about?"
9;Simba Khadder;00:02:59.610;00:03:08.960;00:00:09.350;"It's so much more. I have a billion questions about the search index. But I actually want to jump into data contracts because it's been a hot topic as of late."
10;Josh Wills;00:03:09.110;00:03:09.670;00:00:00.560;"Absolutely."
11;Simba Khadder;00:03:09.880;00:03:12.720;00:00:02.840;"Well, first, how would you define a data contract?"
12;Josh Wills;00:03:13.170;00:03:44.210;00:00:31.040;"It's a great question. My own personal definition, which is a little different than everybody else's, is a data contract is an integration test. It's an integration test. I call it an integration... Integration test, I find it to be the best analogy for it because an integration test is something that's obviously well understood in software systems, and we've been doing for a very long time. I have multiple production components. I test each of them individually, obviously, but I need to make sure that they work together before I push changes to production or continuous integration, that's what continuous integration is."
13;Josh Wills;00:03:45.210;00:04:17.130;00:00:32.280;"For me, that's really what data contracts are. Data contracts are a signal, first and foremost, that your data warehouse and your data pipelines are production infrastructure, which is not true a lot of places, and that's fine. There's a lot of places where I just need to do some basic reporting, and if the reports go down for a day, it's not the end of the world. Then on the other hand, you have everyone else in the world who's doing hardcore machine learning stuff, where if the data pipelines go down, then production goes down with it, or starts degrading in really these nasty ways."
14;Josh Wills;00:04:18.110;00:04:32.910;00:00:15.110;"If you're in that state, if you're in a situation where your data warehouse, your data pipelines are production with a capital P, therefore, you must have integration tests between your upstream production systems and your downstream production systems, just as you would for any other set of components."
15;Josh Wills;00:04:33.870;00:05:00.840;00:00:26.970;"The trick, I think, why we need the term data contracts or why this is hard is that it's been incredibly difficult to really do proper integration testing between the world of production and the world of data. At Slack, we had a web application that was initially in PHP and over time migrated to Hack, which is Facebook's improved PHP implementation."
16;Josh Wills;00:05:01.770;00:05:31.000;00:00:29.230;"Then we had a downstream data warehousing system, which was a fairly classic Netflix-style data lake, Parquet files and S3, lots of Spark, lots of Hive, lots of Presto. These are two completely different, absolutely gigantic engineering systems. Moving data between these two systems involves a Kafka broker that's going to process 250,000 events per second. It's got all this massive data processing infrastructure around it."
17;Josh Wills;00:05:31.470;00:05:50.850;00:00:19.380;"And so how do you come up with a way to do a relatively fast, relatively lightweight set of tests and verification checks between these two systems so you can ensure that when you make a change upstream, you're not breaking stuff downstream? That's the trick, and I think that's the area where a lot of people are still searching."
18;Josh Wills;00:05:50.850;00:06:19.400;00:00:28.550;"When I see people doing data contract stuff, even now in 2023, they're still pretty much inventing their own way of doing it. They're inventing their own interface definition language. They're inventing their own set of tests and stuff like that. That's just where we are. We haven't settled on a standard for this yet, or we simply have not made this easy in any way, shape, or form for people to do without a huge amount of engineering effort, and that sucks. It's basically like, ""This is not a good place to be anyway."""
19;Simba Khadder;00:06:20.150;00:06:21.900;00:00:01.750;"So we've had great expectations for a while."
20;Josh Wills;00:06:22.330;00:06:23.810;00:00:01.480;"We had great expectations. Absolutely, that's right."
21;Simba Khadder;00:06:23.910;00:06:27.840;00:00:03.930;"And we've had even in Kafka, we've had schemas in Kafka for a while."
22;Josh Wills;00:06:27.840;00:06:27.970;00:00:00.130;"Yes."
23;Simba Khadder;00:06:28.030;00:06:43.590;00:00:15.560;"What you're describing seems like it's simultaneous to both of those and more. I just would love to understand. If someone's like, ""Hey, I have a Kafka schema and I have great expectations,"" is that a data contract? Is it not? What's missing from those two?"
24;Josh Wills;00:06:43.590;00:07:25.410;00:00:41.820;"Okay, it's awesome. Fantastic question, Simba. The key differentiator for me, what I think differentiates from your standard Kafka schema, great expectations, DBT tests, whatever it is you do, is basically where is that test happening? Is that test happening prior to a change going to production? At Slack, you could not push a change to production unless the data schema test passed. It simply would not go through. It would fail. It would block your deploy. Or is it the case that you don't find out about the change to the schema or the great expectation test failure until 24 hours later when the data pipeline is running? That is the key differentiator to me."
25;Josh Wills;00:07:25.520;00:07:57.080;00:00:31.560;"If the tests happen before the push to production and can block the push to production, it is a data contract like capital D, capital C. It has teeth, it enforces a blocking change. Whereas if it happens 24 hours later, then it's an audit, it's a test, it's a check. Again, it's not to say it's not important. It's not to say we don't need to do it. We do. We absolutely do because stuff is still going to get through. But for me, it's like that really is that prior to changing the system in production, we make the check. That's the key quality I think for me."
26;Josh Wills;00:07:57.080;00:08:38.169;00:00:41.089;"Again, because the data infrastructure has been so massive and so big for so long, it's just been hard to do that. It's just been hard to like, you can't realistically run a five-tran data extraction, a whole Snowflake pipeline on every single production change when you're doing condition [inaudible 00:08:15]. No one has that much time and money. You could never get anything done. That to me is why we have not done this historically, so yeah. That to me is the clear differentiator, and to me, it's like, if you have those checks ahead of time, then your data warehouse is production, and if you don't have those checks ahead of time, then your data warehouse, while still important, is not production. It just isn't. Period. Yeah, that's me."
27;Simba Khadder;00:08:38.809;00:09:20.020;00:00:41.210;"I think what I'm seeing a lot of recently, and I think we're seeing this paradigm shift where there's almost like has been this dichotomy between production data pipelines and almost like experimentation, where we're just learning about the data, understanding it, analyzing it, playing around with it, especially in ML, there's a very clear experimentation step before you get to production. I feel like tools have always picked one side of the fence. Are you a production tool or are you a production tool? What's been missing, in my opinion, is these workflow tools that make sense on both ends. They are what you would be doing in experimentation, but they're inherently thinking about productionizing."
28;Josh Wills;00:09:20.820;00:10:00.530;00:00:39.710;"I completely agree with you, I think. I think that's exactly right. I feel that tension. I think a lot of folks do. This is something Hamel Hussein and I, who does a lot of notebook stuff and nbdev and stuff like that, have talked about a lot because he is deeply interested in this divide. I think a large part of it, Simba, is that software engineers, generally speaking, do not grok the experimental interactive nature of a lot of data work, especially a lot of machine learning work. It just does not make sense to them because it doesn't describe their work. They use an IDE, they don't use a notebook, and it just does not compute. It just doesn't."
29;Josh Wills;00:10:01.160;00:10:25.160;00:00:24.000;"Simultaneously, I think folks who do a lot of experimentation and interactive development stuff do not have a great mental model for how to do automation and reproducibility and stuff very well, so we're stuck here. These two worlds just completely talking past each other, and it's deeply, deeply frustrating for folks. I know it's frustrating for everybody. I should probably be doing more here. I feel I've been fortunate to live on both sides of this divide."
30;Josh Wills;00:10:25.890;00:11:04.820;00:00:39.220;"I don't know the solution here. I'm open to suggestion, I guess, is what I want to say here. I'm not saying this is not an easy problem. If it was, we would have solved it already. It's legit hard. How do you respect and enable and support that experimental iterative, try it, just get almost like the flow state in some sense of working with a data set, working with a model, while also being militant about reproducibility? It's just hard, man. It's just hard. Do you have thoughts here? Have you all thought about this? I just be curious. I don't mean to turn the interview back around on you, but I'm very open to ideas here is what I want to say."
31;Simba Khadder;00:11:05.490;00:11:38.500;00:00:33.010;"Yeah. I mean, it's a big promise of what we call the virtual feature stories to solve that piece for ML. The whole concept is it should be when you're iterating, all that we, let's call it, let's say force upon the data scientist, is that you use this almost function framework. Rather than just writing your query or your payment transformation or whatever, raw notebook, you just tab it, give it a function, that function name becomes the name of that transformation. You can later add versioning and other things to form productionize it."
32;Simba Khadder;00:11:38.900;00:12:12.640;00:00:33.740;"The goal would be over time that the iteration, the deployment, there would be slightly different modes, but I almost think of it or liken it to a Django or something, where it's just like if you follow this framework, it will automatically make it very easy to productionize while making it feel like you're running this presentation code. Now, the difference between a Django and what we're doing is that, like you said, Django is a linear process. I need this new REST call, it does XYZ, where with data science and with feature engineering, there's a lot of like..."
33;Simba Khadder;00:12:12.990;00:12:33.670;00:00:20.580;"If someone told me that, ""Hey, I spent a month going down this project,"" and I realized with the data we have and everything, it'd actually be impossible to create a model that does this, I'd be like, ""Great, that's a good use of time. We figured out this thing's impossible."" If a software engineer told me, ""Hey, I took a month doing this, and we're throwing it all away,"" I would be like, ""Dude, no, you can't."" [crosstalk 00:12:33]."
34;Josh Wills;00:12:33.570;00:13:02.400;00:00:28.830;"That's right. See, that's exactly it. That's the key right there. That's a great point. Yeah, totally. I'm thinking of like, I find it very instructive to think of extreme cases of people tackling this problem. I think a lot of Netflix in this way, and the work they have done to make notebooks production things. It's Paper Mill, I think is the name of their tool, and they have some other stuff like that."
35;Josh Wills;00:13:02.510;00:13:49.700;00:00:47.300;"Then the other thing they did, which I just still boggles my mind, was just to get the feature data for their training pipelines. They would literally query the production systems from the training environment. It's just the thing that just sounds absolutely insane to me, but it's part and parcel of their chaos monkey engineering culture where, ""Hey, the machine learning team is going to do 90,000 RPCs to your service in an hour. Hope that's cool."" And it's just like, yeah, that's just what they do. Anyway, I get a kick out of stuff like that. I don't recommend anyone do that. It's absolutely fascinating the ways that they think about to tackle these problems and stuff. Anyway, yeah."
36;Simba Khadder;00:13:49.700;00:13:58.980;00:00:09.280;"Well, maybe a question there would be where do notebooks fit in? Do notebooks fit in production? Obviously, I think we both agree that they're an integral part of the experimentation pipeline."
37;Josh Wills;00:13:58.980;00:14:02.680;00:00:03.700;"I mean, absolutely. Where do they fit in or should they go in production?"
38;Simba Khadder;00:14:02.860;00:14:03.350;00:00:00.490;"Exactly."
39;Josh Wills;00:14:03.390;00:14:37.660;00:00:34.270;"I think it's like you're talking to me, Simba, when I'm mid-conversion. I have been a long-time notebook hater. I've been very anti-notebooks for a really long time, and I am basically slowly coming around, I think. Obviously, a lot of other people have been messing around with a lot of large language models a lot, and doing this stuff on their notebook is just pure joy. It's like me and my Jarvis hanging out, hacking together. You know what I mean? I'm just loving it, and so it's changing the way I think about this stuff."
40;Josh Wills;00:14:37.660;00:15:13.970;00:00:36.310;"I have not quite become the full-throated advocate convert. There's no evangelist like the convert or whatever the quote is. I haven't quite gotten there yet, but I do very much feel like I was wrong. Notebooks are actually great, and especially in the large language model-centric future I believe we are headed towards, they are going to play an outsized role in how we work, not just as data people, machine learning people, but just as people. As human beings, I suspect that some notebook-like thing is going to become a bigger way that we work going forward."
41;Josh Wills;00:15:15.150;00:15:40.130;00:00:26.090;"In that world, I think for me, it's time to reexamine systems like paper mail. It's time to really start thinking hard about how do we make these things... I don't know. How do I make these things work as much like the boring, good old reliable cron jobs that I've written in Python that I've been running for years and years and years? But I don't know that I have the answer yet, other than say that I was wrong and I'm coming around. And I'm, again, super interested in figuring out ways to solve this."
42;Simba Khadder;00:15:40.190;00:15:45.330;00:00:05.140;"I'm curious to get your feedback. I'm similar. I actually am like-"
43;Josh Wills;00:15:45.330;00:15:45.330;00:00:00.000;"Kind of the same thing?"
44;Simba Khadder;00:15:45.330;00:16:06.630;00:00:21.300;"Yeah. I was like a very like... Part of it, I think, is because I was in ML for building recommender systems. We're doing a hundred million MAU. We're doing all kinds of transformer-based or user embedding and training. I'm embedding doing all kinds of fun stuff. I come from Black Hat Google. At Google, I wrote both PHP and X86 at different points in my career."
45;Josh Wills;00:16:06.630;00:16:12.420;00:00:05.790;"That's drawing. That's wow. Okay, good. That's two really truly terrible programming languages for you to know. I'm kidding."
46;Simba Khadder;00:16:12.900;00:16:14.950;00:00:02.050;"I've worked on both. I've worked on... It's like the horseshoe."
47;Josh Wills;00:16:16.130;00:16:16.230;00:00:00.190;"[crosstalk 00:16:16]."
48;Simba Khadder;00:16:18.340;00:16:18.970;00:00:00.630;"Exactly."
49;Josh Wills;00:16:18.970;00:16:20.520;00:00:01.550;"Yeah, got it. Okay."
50;Simba Khadder;00:16:20.540;00:16:46.940;00:00:26.400;"So I came from like, I didn't use notebooks, I used Python files. That's how I worked. And I definitely was converted to like, ""Hey, notebooks are just such a better way to do this."" But then I was in the same boat of like, ""But these things should be nowhere near production."" My take now, which again, I'm curious to get here, is notebooks are where you should be building things, but you should be taking these artifacts that you create and exporting them somewhere else."
51;Josh Wills;00:16:47.280;00:16:47.990;00:00:00.710;"Yes. Okay."
52;Simba Khadder;00:16:47.990;00:16:49.230;00:00:01.240;"Do you buy that?"
53;Josh Wills;00:16:49.500;00:17:30.850;00:00:41.350;"I broadly do. I think that's where I've ended up with this stuff. And again, just hanging out with folks has introduced me to nbdev and CORDA and all these other things of mechanisms for taking my exploratory stuff and then crystallizing it into some structure that's designed for reproducibility and runability without me sitting at the keyboard to guide the cell execution and stuff like that. I think that's right. I think it's just like, I don't feel like I've seen yet is, what's the right gesture, almost, in the way that GitHub introduced the pull request as their fundamental innovation, the social action you can take."
54;Josh Wills;00:17:30.880;00:17:54.820;00:00:23.940;"I have to be honest with you, whenever I hear about or read about a framework or something, immediately I'm just seized up with fear because I feel like it's going to harsh my vibe. It's going to mess up my workflow. It's not going to be like... It's going to be this constraint that's going to... It's one of those things where to a certain extent, a framework can give you freedom. The constraint can set you free in other ways and stuff like that."
55;Josh Wills;00:17:54.820;00:18:20.520;00:00:25.700;"But it's just my instinctive response of like, ""Hey, Notebook is this free-for-all exploratory whatever, and you want to come along and impose rules and strictures on me,"" and it's like, ""I'm not going to be able to come up with the next great neural architecture because I'm going to be stuck."" You know what I mean? Which isn't rational, but it's just my emotional reaction to that stuff. I can't imagine. I'm vocalizing this. I don't feel like I'm the first person to feel this way, though. Does that make sense?"
56;Simba Khadder;00:18:20.580;00:18:38.250;00:00:17.670;"Yeah. I think it's totally true. I think what it is, we've all seen the mad landscape thing. I always joke, if you take that and you have to narrow it down to products that data scientists love to use, actually truly love to use-"
57;Josh Wills;00:18:38.260;00:18:39.250;00:00:00.990;"Truly love to use, exactly."
58;Simba Khadder;00:18:39.270;00:18:43.890;00:00:04.620;"-it would be like 10. It just would cut down dramatically."
59;Josh Wills;00:18:45.440;00:18:45.840;00:00:00.400;"Totally."
60;Simba Khadder;00:18:46.310;00:18:58.340;00:00:12.030;"I think people who build Dev tools are engineers. Engineers, as much as we like to pretend we're rational creatures, we are very, very emotionally driven-"
61;Josh Wills;00:18:58.340;00:18:59.490;00:00:01.150;"Very much so."
62;Simba Khadder;00:18:59.490;00:19:05.730;00:00:06.240;"-and we feel like, ""Well, I like it this way, or I want it this way, so therefore, I'm going to do it this way. And if you don't agree with me, you're dumb."""
63;Josh Wills;00:19:06.180;00:19:07.050;00:00:00.870;"That's right."
64;Simba Khadder;00:19:07.050;00:19:33.810;00:00:26.760;"I think that lots of the frameworks that get built, in general, they tend to be overengineered. Because again, the other thing that we like to do is if someone's like, ""How have they did this?"" We're like, ""Cool, we can do that."" And we never ask ourselves, ""Should we do that?"" That's because we can, doesn't mean we should. And I think that a lot of times, like, we just did this meet up with Sebastian at FastAPI, and one thing I like about FastAPI is it's very simple. It's very lightweight. It doesn't feel like it's getting in the way."
65;Josh Wills;00:19:33.810;00:19:41.590;00:00:07.780;"It's just fantastic. I love it so much. Absolutely. You're talking about tools, 10 tools people love. FastAPI, without a doubt. One hundred percent in my tent. Absolutely."
66;Simba Khadder;00:19:41.640;00:19:54.690;00:00:13.050;"I think most products wouldn't fit that. I don't think that's necessarily that, hey, frameworks are a bad thing. It's just getting a framework right. API design is one of the hardest problems."
67;Josh Wills;00:19:55.010;00:19:55.890;00:00:00.440;"Totally."
68;Simba Khadder;00:19:55.010;00:20:18.930;00:00:20.940;"People like to jump into and be like, ""Well, just add this function call and it's done."" It's an art and it's a craft, and people who are really good at it are few and far between. You see the same people who build Go, whether you like it or not, are also similar people who are huge on Unix. That's how rare it is to find good API people. We have to go source people from olden days of [inaudible 00:20:16]."
69;Josh Wills;00:20:17.110;00:20:30.070;00:00:12.960;"Yeah, exactly. Richie, absolutely. Like Rob Pike, yeah, totally. Yeah, I know what you mean. Sad but true, Simba. Sad but true. Alas, I like to think we can do better here. But okay, I hear you. I hear what you're saying. That's fair."
70;Simba Khadder;00:20:30.620;00:20:43.880;00:00:13.260;"Yeah, I think that's all it is. I don't think it's to say that frameworks are bad. I just think having really good frameworks is really hard, and it's so hard that there's probably one in every hundred that even are-"
71;Josh Wills;00:20:43.920;00:21:10.720;00:00:26.800;"One of my weird system... Also, like former Googler. I was there from 2007-2011. I had the privilege... I had two weird privileges at Google. One was Rob Pike did my first code review at Google. First code review. I added a couple of libraries to [inaudible 00:21:02] for doing various kinds of non-parametric correlation calculations, like Spearman correlation and then stuff like that, for some work I was doing."
72;Josh Wills;00:21:10.720;00:21:41.340;00:00:30.620;"That code review, Simba, went on for 30 days. Thirty days, and maybe 50 odd revisions, Rob Pike. I'll never [inaudible 00:21:19] the last one he did [inaudible 00:21:20] change. I had some bounds checking function I was using, and he had me reverse the arguments because he liked the way it looked better. I was like... It was amazing, Simba, that I did not quit after that code review. Looking back on it, if I had any... The good news, I was young and I had a very fragile ego and stuff. In retrospect, I probably should have quit, but I didn't."
73;Josh Wills;00:21:41.620;00:22:11.600;00:00:29.980;"The other thing, I was invited to the very first technical talk from Rob Pike and Russ Cox about Go. I got to go. It's like all the most senior engineers of the company and also me, I'm also there for some reason, basically. I remember just the decidedly meh reaction from so many people in Kegel. We're like, ""Yeah, go, it's okay."" I guess they may have gotten some things right and stuff like that."
74;Josh Wills;00:22:11.850;00:22:44.990;00:00:33.140;"Overtime, obviously, Go has been incredibly successful and has completely found its community and stuff like that. I think that's the other part here, is the tool has to fit the hand. A lot of those hardcore C++ developers were just not the people that were... They were just not going to adopt Go. It was just never going to happen. They're all like, ""Whatever, not that good."" But then it found its community, and as it did, it grew accordingly. It's like figuring out that match between the tool and the community to wield it. It's just so critical and so hard to get right."
75;Simba Khadder;00:22:45.460;00:23:00.010;00:00:15.290;"Yeah. Actually, funny enough, a funny connection, I worked on the same floor as Rob Pike for a while. He was pretty close to me, so I used to play [inaudible 00:22:52] in the microkitchen. I luckily never had to deal with his code reviews, but was not surprised that that [crosstalk 00:22:59] would be the experience."
76;Josh Wills;00:23:00.780;00:23:06.380;00:00:05.600;"Absolutely brutal, humbling, humiliating experience without a doubt. Yes, exactly."
77;Simba Khadder;00:23:06.380;00:23:16.710;00:00:10.330;"Yeah, for sure. But also you need to be that much of a perfectionist to build these sorts of APIs. It doesn't mean that you should be building everything, but if you're building, it's this funny balance."
78;Josh Wills;00:23:16.730;00:23:51.290;00:00:34.560;"I go back and forth and I like to think that Google broke me of my egotistical identification with my source code of where... It broke me of the notion that the code I wrote was an extension of my own personality and then anything wrong with it was something that was deeply wrong with me. Google, to its credit, in a basic training way, broke me of that belief and showed me that it's not. This is a company. The source code is our product. We all build it together. We are all responsible for it, and so on and so forth. Just one of those useful life lessons we take away from these horrible experiences."
79;Simba Khadder;00:23:52.550;00:23:56.470;00:00:03.920;"Yeah, I wasn't in Google very long either for probably sounds like similar reasons."
80;Josh Wills;00:23:56.900;00:24:01.220;00:00:04.320;"I was there for almost four years. Is that not very long? I don't know. Is that not?"
81;Simba Khadder;00:24:01.220;00:24:02.890;00:00:01.670;"I think that's pretty long."
82;Josh Wills;00:24:02.890;00:24:06.040;00:00:03.150;"It's probably pretty long, right? It felt long. I'm not going to lie, it felt long."
83;Simba Khadder;00:24:06.480;00:24:21.860;00:00:15.380;"I want to jump into another... I want to take the conversation to LLMs because it's a hot topic. Well, first, tell me about them. Is this transformational? Is this a whole new paradigm we're dealing with? What's going on? What's your take?"
84;Josh Wills;00:24:22.400;00:24:54.310;00:00:31.910;"Yeah, I mean, yes. The answer is yes. The hype around LLMs is so off the charts right now that you have to properly calibrate yourself in terms of where you are in the hype cycle. I guess I divide this into the two main framings. I think of this, this is as big of a deal as a mobile phone. This is the next dominant paradigm that will reshape society and stuff like that in the same way that the mobile phone did 15 years ago. That's one level of hype, and that's a pretty big level. That's a lot of hype. Mobile phones, really big deal. Change a lot of stuff."
85;Josh Wills;00:24:54.310;00:25:39.960;00:00:45.650;"The next level of hype, though, and I have friends who inhabit this level, is this is electricity. This is akin to us in the light bulb or Edison and Tesla and stuff, way back in the day. It's that level of impactful. I have some friends who are on that level. I think I've maybe flirted a bit with the electricity level of transformativeness. I don't feel like I'm there right now. I'm definitely well above the, this is bigger than the mobile phone level of hype, but I'm not quite on the, this is electricity level of hype. That's where I'm hanging out right now. Somewhere in the muddy middle in between those two extremes. It's a very big deal. I think it's going to reshape all kinds of things in ways that are very difficult to predict."
86;Josh Wills;00:25:39.960;00:26:36.950;00:00:56.990;"Just in terms of our own lives, it seems fairly obvious to me that we will all have... I mentioned the Jarvis thing before because obviously I pay for a GPT-4 subscription, and so I hang out a good part of the day talking to my GPT-4 instances. We're hacking away on stuff. I feel like having that Jarvis level in the Iron Man sense relationship for everybody on our phones in the next year or two is just a given. I find it fascinating to think through the implications of that. Is it going to be like, if you and I want to do a podcast together, is it going to be our Jarvises coordinating the podcast? Is it going to be the Jarvises doing the research ahead of time? Will the Jarvises be here with us on the podcast weighing in on things? Do you and I even need to be here? Can the Jarvises just do it for us? All this stuff. This is the stuff I find myself wondering about these days."
87;Simba Khadder;00:26:37.590;00:26:45.070;00:00:07.480;"Yeah, I can't wait for my Jarvis to be like, ""Simba, that's factually wrong. I just looked [crosstalk 00:26:42]."" Yeah, exactly."
88;Josh Wills;00:26:45.500;00:27:02.240;00:00:16.740;"Knowing myself as I do, my Jarvis will be absolutely hypercritical and borderline cruel against me. If I could come up with a software manifestation of my imposter syndrome, that's exactly what it would be. That's great."
89;Simba Khadder;00:27:02.270;00:27:05.840;00:00:03.570;"That would be a good app name for it to imposter."
90;Josh Wills;00:27:05.860;00:27:06.680;00:00:00.820;"Precisely."
91;Simba Khadder;00:27:06.680;00:27:10.690;00:00:04.010;"I like the analogy electricity versus the mobile phone."
92;Josh Wills;00:27:10.690;00:27:11.290;00:00:00.600;"Mobile phone."
93;Simba Khadder;00:27:11.290;00:27:32.850;00:00:23.560;"I think what's interesting there, which makes it maybe almost like... It actually made the analogy even more interesting in my head is electricity, like you mentioned, you go back to Edison. That's a long time ago, and it took a while before... I don't think even then there were people like, ""Hey, this is the transformative of us like oven."" [crosstalk 00:27:32]."
94;Josh Wills;00:27:33.140;00:27:35.280;00:00:02.140;"The wheel, exactly."
95;Simba Khadder;00:27:35.280;00:28:04.020;00:00:28.740;"Yeah, exactly. I wonder how much... As things accelerate, maybe it's like the mobile phone now, but we'll look back. This was such a primitive form of what is to come. It's how I think of electricity where... Obviously electricity was huge foundational change, but I don't know if I've ever until this conversation really thought of it as more foundational than the mobile phone as much as we just continuously build on [crosstalk 00:28:02] the shoulders of science and over time."
96;Josh Wills;00:28:04.020;00:28:44.820;00:00:40.800;"For me, the book I'm going to recommend here, which I love, is called Empires of Light. There was actually a really bad movie based on Empires of Light. It was called The Current War about the war between Edison and Westinghouse/Tesla over direct current versus alternating current. Again, I worked at a company called WeaveGrid for a couple of years after I left Slack. I was selling software for utilities for managing electric vehicles. I have a weird nerdy obsession with the utility grid and the history of the grid and stuff like that. That fed into my desire to work on this kind of stuff."
97;Josh Wills;00:28:45.010;00:29:24.320;00:00:39.310;"Yeah, Empires of Light, absolutely a fantastic book about what the early stages of the industrial use of electricity and how it changed society. The thing, I guess, that was most fascinating to me about, it was really... What electricity did first was it allowed us to create time, in the sense that electric light made days longer. That's just one of those things that's hard to wrap your head around at first. It literally created time. Hours of the day that were not available for doing things suddenly were available for doing things, which is amazing."
98;Josh Wills;00:29:24.620;00:29:46.930;00:00:22.610;"The other thing which is remarkable about it is how long it took for these innovations to reach everywhere. The start of the book is talking about J.P. Morgan having the first electrified house in New York City and literally running a coal plant in his basement to power the thing. He has coal and smoke belching out the back of his house from running this electrical system."
99;Josh Wills;00:29:47.000;00:30:31.890;00:00:44.890;"But then how it was not until the new deal, which was 50 or 60 years later before electrification reached out into rural environments in the United States, and basically everybody had electricity. It was not until the 1940s or '50s. It took a really long time for this stuff to get out everywhere. I think about this stuff with LLMs a lot. I think of this as like, we're in the early days of like, you have an LLM, I have an LLM. It's obviously spreading so quickly, but I'm just curious to think about how long will this take to reach everyone in the world? Again, where literally everybody has a Jarvis. Every human being on the planet has a Jarvis. Is it 60 years? Is it a decade? I'm like, ""What is it?"" I'm not really sure anyway."
100;Simba Khadder;00:30:32.210;00:30:46.300;00:00:14.090;"Yeah, it makes me think of two things. One, with regards to the time, the increase of time. Also, a quick side note, I feel like so much of how the US works today was foundationalized during that industrial revolution."
101;Josh Wills;00:30:46.350;00:30:46.850;00:00:00.500;"Totally."
102;Simba Khadder;00:30:46.920;00:31:31.340;00:00:44.420;"It's really interesting to read about all that stuff because it's almost like this long running cascading effect that you can almost trace back to these innovations. Literally from how finance works all the way to, you said, electricity, was all the foundations were set, I guess, over 100 years ago now. The time example is interesting because it relates to, well, even if you have more time, you still go to sleep and it goes to what we're catching up. I think it almost applies here about LLMs too, where it's just because we can do all these things... The one thing that we can't easily update yet, and who knows, is the wetware, and our cells, essentially, how our brains work and process and do these things."
103;Simba Khadder;00:31:31.360;00:32:06.340;00:00:34.980;"I think it'll be interesting to see that come into play too, especially if we start to get to this point where we do find LLMs that are, I guess, stronger. Like you mentioned, having them do the podcast for us. It's like finding where we... I think we're always away from them being that powerful. But it's definitely opened the questions up as we hit this new inflection point of... I liken it to the new technology. It's almost like the straw that broke the camel's back in the sense of from a research perspective, the techniques that we're using to create these LLMs aren't necessarily..."
104;Simba Khadder;00:32:06.400;00:32:43.560;00:00:37.160;"They're new, but they're more of an extension of something. It's not like this is a whole new like, ""Oh, we just changed everything from yesterday to today. We just invented this new concept."" It's more about the concept we've gotten so good and have fine tuned it so much and gotten so good at building these transformer based architectures that we now have passed this, I guess, valley of disbelief from when humans interact with it. It's just gotten so good that it's like, ""Cool, I see the light now."" It's not you pitching me something and then I look at the product, I'm like, ""Yeah, no, this isn't AI."" It's finally like, ""Okay, it's still imperfect, but it feels unlike what we were seeing before."""
105;Josh Wills;00:32:44.060;00:33:26.530;00:00:42.470;"It's certainly imperfect. I think on the podcast point, there's now the Joe Rogan AI Experience, which is a purely AI driven podcast featuring an AI Joe Rogan talking to an AI, Sam Altman, and stuff. This is here. This happens. You and I obviously are not important enough to have an AI talking for us, basically. We're just two idiots, right. But it doesn't seem that far off to me, I don't think. Before this, this is... If we want, you can just like, ""I'm happy to just send my AI over to you. Here's your budget for how much computer you're allowed to use to have me generate answers and stuff like that."""
106;Simba Khadder;00:33:27.290;00:33:36.960;00:00:09.670;"I think that actually opens to the next point which you mentioned about use. I actually think that a lot of what we're doing now is essentially subsidized by Microsoft and others."
107;Josh Wills;00:33:37.640;00:33:39.140;00:00:01.500;"Without a doubt."
108;Simba Khadder;00:33:39.680;00:34:32.520;00:00:52.840;"There's no way that they're making profit off of what you're spending for GPT-4. That's only on the cost of goods. That's just literally on the electricity and the GPU time. That's not ignoring all the work that goes into actually building these things. I think that's going to be a big question too, is almost, even if this is foundational, once economics come into play, it becomes a lot harder to justify having this constantly running large neural network that answers everyone of your ridiculous questions that you come up with as you're standing. I think that's where lots of the professional use cases are probably going to find more widespread use because you can make the economic argument there. I feel like the personal Jarvis will be a thing that is left to people who can spend 10, 20-"
109;Josh Wills;00:34:32.520;00:35:10.150;00:00:37.630;"Yeah, like the J.P. Morgan's of our day, I think, at first. But people will just be super incentivized to figure out how to make this stuff cheaper and how to make the hardware better and all that stuff. Is it tomorrow? We all have a Jarvis? No, of course not. Is it 10 years from now? Yeah, I'm pretty sure. Is it five years from now? Maybe. Not quite sure. It gets fuzzy. It's the cliche about you overestimate what can be done in a year and underestimate what can be done in a decade. I suspect we're in that part of the hype cycle right now. We're overestimating what can be done in a year and underestimating what can be done in a decade."
110;Simba Khadder;00:35:10.180;00:35:57.900;00:00:47.720;"I agree. I think it's almost like CPUs where it's almost like we kept going and going and speed, speed, speed. Then all of a sudden, we got to this point where it's like, hey, actually speed isn't what matters anymore. It's energy efficiency. It's this other concept. I think that's where we just got. We're like, ""Hey, these things are starting to get plenty accurate."" It's not really the issue anymore. It could always do better for specialized use cases, but it's probably way higher ROI to figure out how can we do what we're doing now but with significantly less parameters. I think it's been a known thing for a while, but I think we've finally gotten to the point where it's not an interesting niche point of research. It's actually become like, ""Hey, if you pull this off, you're going to make a lot of money."""
111;Josh Wills;00:35:57.900;00:36:01.140;00:00:03.240;"There's a pot of gold waiting for you. Absolutely. Exactly right."
112;Simba Khadder;00:36:01.140;00:36:13.150;00:00:12.260;"How do you think bringing LLMs back to data? How is this going to change how people do data, how LLM works? It's just LLM done for? Where are we at in that sense?"
113;Josh Wills;00:36:14.010;00:36:28.780;00:00:14.960;"This is a question I've been thinking about a lot since I was... I've been anticipating being asked this question on podcasts and stuff like that. You know what I mean? I've been giving this a lot of thought. I have two thoughts here. Again, this is early, and again, I can be completely wrong about this stuff."
114;Josh Wills;00:36:29.100;00:36:57.340;00:00:28.240;"My first thought, at least in particular with data, as it portends to data and data analysis and so on and so forth, for a long time, data engineering has been focused on data modeling, and how do we model data for human consumption, for BI tools? We do look ML, we do semantic layers, we do dimensional models. We model data to make it interpretable, approachable by humans and so on and so forth."
115;Josh Wills;00:36:57.740;00:37:27.540;00:00:29.800;"With LLMs, I think you're starting to see that conversation shift to not... Basically, we're not going to model data for humans anymore. We're going to model data for the large language models. Large language models will be the target audience for our data models. Some folks have been talking about activity schema. The activity schema pattern is a better model, perhaps, for how would we make data consumable, where the large language model doesn't really care about a bunch of stuff that a person cares about?"
116;Josh Wills;00:37:27.540;00:37:54.590;00:00:27.050;"A large language model doesn't care that the table has a thousand columns in it. It doesn't care. It doesn't make any difference. It makes a lot of difference to a person. A person sees a thousand columns, they're like, ""Oh, my God. What's going on here?"" But the large language model doesn't care. Therefore, activity schemas, or these other, I would say non-standard data models, data models that aren't as popular with the classic BI tools and stuff like that, will be in ascendence as we build for large language models."
117;Josh Wills;00:37:54.610;00:38:30.010;00:00:35.400;"I would take that one step further, though. I think that the engineering problem will no longer be how to engineer the data models. It will be like, how do I engineer a data analyst? How do I build... Using the large language model as a primitive and my own understanding of the business and the context and all the stuff, these tools available to me, how would I synthesize an actual data analyst? The persistent problem in data for a long time has been the shoulder tap phenomenon like, ""Hey, can you just pull some data for me on this thing real quick, data analyst person?"""
118;Josh Wills;00:38:30.240;00:38:50.250;00:00:20.240;"It's super annoying and data analysts hate it. It drives them crazy. They're basically a SQL generator that spits out Excel spreadsheets or whatever with data pools. But the large language model is not going to care. The large language model is going to be super happy to do that. Literally nothing will make the large language model happier than spitting out some SQL and sending you an Excel file on it."
119;Josh Wills;00:38:51.400;00:39:28.730;00:00:37.330;"I think that engineering a system to do that, to build a system to do that with business context, with the data itself, with the tools available is the next grand challenge of data engineering. I think someone's going to figure out how to do that. Similarly, for machine learning models, my historical experience for machine learning has been similar to yours. I've worked on ad click prediction systems. I've worked on recommender systems. I've worked on fraud detection systems, spam detection systems. Very classifier heavy stuff where there's lots of feature engineering, [inaudible 00:39:23], and like ""Let's gather more data and let's run it through XGBoost and let's go do our thing."
120;Josh Wills;00:39:28.730;00:39:51.370;00:00:22.640;"I'm imagining that same workflow applying here where the large language model is like yet another machine learning engineer and we're giving it these classification problems. It's sitting there and it's cranking stuff out and trying out features and different weights and different algorithms and stuff. That's what it does all day. Quite possibly reporting back to me in a notebook environment, what exactly it's been up to. That sort of stuff."
121;Josh Wills;00:39:51.560;00:40:13.370;00:00:21.810;"That, for me, it's a weird thing to say, I think, but it's data engineering, ML engineering moving from empowering data analysts or making them productive to essentially replacing a large part of the most tedious and awful part of their job with a software system that just is built to do that role. That's thing one that's interesting."
122;Josh Wills;00:40:13.370;00:40:35.970;00:00:22.600;"Thing two that's interesting to me is how this changes the landscape. I have this mental model in my head when it comes to the data tools market, which is what I spend most of my time thinking about. In the data tools market, there is ingestion. There's the Airbytes and the Fivetrans, the Notanos, that get data from source systems and move it into a data warehouse."
123;Josh Wills;00:40:35.970;00:41:00.000;00:00:24.030;"And then there's the BI tools. There's your Mode and your Tableau and your Looker and all those things. And in the middle, the absolute star of the show, the sun that everything else revolves around is the cloud data warehouse. It is the Snowflake, BigQuery, Redshift. I said Big Shift, that's fantastic. BigQuery, Redshift, Postgres, whatever else it is you like to use."
124;Josh Wills;00:41:00.270;00:41:29.190;00:00:28.920;"I can't help but wonder how that looks, how that model works going forward. It seems to me the most likely place for... If I want to inject a large language model into this stack, ingestion, cloud data warehouse, BI, where does it go? It seems obvious to me that it goes in the BI layer. It goes in the presentation analysis layer. That's where it goes. And once it's there, what happens to the rest of the stack?"
125;Josh Wills;00:41:29.190;00:41:55.040;00:00:25.850;"I feel like the center of gravity, the most important system for so long has been the cloud data warehouse. But I think that LLMs end up shifting that over to the BI side of things. The BI tool becomes the most important thing in the world. I maybe don't care so much anymore about how the data is modeled or what the back-end cloud data storage system is, because I don't know anything about that. It's not designed for me anymore. It's designed for the large language model that's powering the BI tool."
126;Josh Wills;00:41:56.150;00:42:13.580;00:00:18.540;"To me, it's like, what about the stack has to change in order to allow us to effectively incorporate large language models and make them more effective at their jobs? Again, I don't know, but I think it's going to shift the balance of power towards the BI side and away from the cloud data warehouses. That's my rough sense."
127;Simba Khadder;00:42:13.580;00:42:29.430;00:00:15.850;"I think that makes a lot of sense. You could argue that that's where the final business value comes from. Just having stuff deployed doesn't inherently drive value. It's more the things you do with it. It always made sense that eventually it falls into a commodity category."
128;Josh Wills;00:42:29.460;00:43:00.040;00:00:30.580;"It does, but it hasn't so far. And [crosstalk 00:42:31] has done a fantastic job of not letting that happen by being better at integrating storage and compute together to handle large volumes of data and do all this great stuff. You need something as disruptive as large language models in order to shift the balance of power here. It is up there with the mobile phone changing the way we develop software and stuff like that. It has to be something on that magnitude. Otherwise, things would just go on the way they always have, more or less."
129;Simba Khadder;00:43:00.040;00:43:18.700;00:00:18.660;"I agree. I think that's what we're saying. I think that another company, Databricks, I think has always done a very good job of moving up the solution stack. They've done a lot to make sure they're not just like Spark and that they get as close as they can to being actual... I don't know if they have a BI tool, but I wouldn't be surprised if they did [crosstalk 00:43:18]."
130;Josh Wills;00:43:18.780;00:43:24.210;00:00:05.430;"They have a notebook-based system, of course. Of course, they do. You need notebooks and Databricks, absolutely."
131;Simba Khadder;00:43:25.920;00:43:27.400;00:00:02.330;"Now [inaudible 00:43:26] Dolly, or what's their..."
132;Josh Wills;00:43:27.430;00:43:27.630;00:00:01.220;"Dolly. Yeah, Dolly is their... Absolutely."
133;Simba Khadder;00:43:29.240;00:43:34.390;00:00:06.120;"Yeah, it's Dolly. Now I'm thinking of Dolly, I immediately thought of the old DALL-E, the image one. That's how fast I guess gen AI."
134;Josh Wills;00:43:34.980;00:43:44.780;00:00:09.800;"DALL-E, that's super great. That's super funny. I've been reading about Databricks' Dolly, and I didn't even make that connection. I thought they were doing it as a reference to the sheep that was cloned or whatever."
135;Simba Khadder;00:43:44.780;00:43:53.210;00:00:08.430;"I think they are. I've never, ever made that reference. Right now, when I said it, I'm like, ""Did I say that wrong?"" I think I've never thought about it while saying it. I just-"
136;Josh Wills;00:43:53.210;00:43:57.190;00:00:04.810;"I didn't either. That's fantastic. I didn't get that."
137;Simba Khadder;00:43:58.380;00:44:00.630;00:00:03.990;"I think that makes a ton of sense. It just flew up."
138;Josh Wills;00:44:02.370;00:44:27.790;00:00:25.420;"Databricks, to me, is... I think this is the other great question here, which is that I love seeing the Dolly stuff that Databricks is doing. Databricks is very much incentivized to live in a world in which everyone trains their own large language models. That is a much better outcome for the world for Databricks than a world in which there is only one model. There's GPT-7 or whatever, and that's it. That's the only model and everyone uses GPT-7 to do everything."
139;Josh Wills;00:44:28.020;00:44:42.400;00:00:15.100;"So it's like, I get where they're coming from. Going that approach 100% makes sense for their business and all that good stuff. It's hard for me to know right now whether there will be one model to rule them all or whether everyone will have their own model and stuff, and I can make the [crosstalk 00:44:42]."
140;Simba Khadder;00:44:43.120;00:45:06.950;00:00:25.340;"I think we'll give it away once the economics come into play. Once you're cool, you can't just raise however many billions of dollars you fund. You have to start cashing in a bit and start to actually charge what you're actually... I'm sure there's a handful of people in the world that know, but I don't know how much each query costs OpenAI, but it's probably a lot. It's probably a lot more than we think."
141;Josh Wills;00:45:08.460;00:45:21.650;00:00:14.450;"I'm sure it is not cheap. It seems like these days the scarce commodity is not money, obviously. The scarce commodity is literally GPUs. There was a good article about that in The Information. Just getting the GPUs is physically difficult to do right now, unfortunately."
142;Simba Khadder;00:45:23.250;00:45:25.950;00:00:02.700;"Yeah, we'll start trading GPUs for food."
143;Josh Wills;00:45:26.880;00:45:31.020;00:00:04.740;"It honestly wouldn't shock me to see that. Yeah, exactly. Precisely."
144;Simba Khadder;00:45:31.620;00:45:36.010;00:00:05.600;"Awesome. Well, Josh, I thought we'd keep going for a long time, but I do need to cut this off."
145;Josh Wills;00:45:37.220;00:45:37.870;00:00:00.330;"You have a job. You have things to do."
146;Simba Khadder;00:45:37.220;00:45:37.870;00:00:00.000;"Unfortunately."
147;Josh Wills;00:45:37.870;00:45:39.210;00:00:02.040;"Exactly. Yeah, totally. I understand."
148;Simba Khadder;00:45:39.910;00:45:46.250;00:00:06.980;"My driver will be here talking with you and maybe we'll bring you back on for another one of these. Maybe we'll do like, where did we end up on this in however long?"
149;Josh Wills;00:45:46.890;00:45:52.770;00:00:06.870;"Totally. I would love to listen to this conversation in six months or a year and just absolutely cringe at how wrong I was about it."
150;Simba Khadder;00:45:53.760;00:45:55.280;00:00:01.960;"Well, thanks again for hopping on. It's been a pleasure."
151;Josh Wills;00:45:55.720;00:45:58.800;00:00:03.080;"Thanks for having me, man. This was fun. I appreciate it."
