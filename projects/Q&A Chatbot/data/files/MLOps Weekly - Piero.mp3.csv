Number;Speaker;Start time;End time;Duration;Text
0;Simba Khadder;00:00:06.100;00:00:42.410;00:00:36.310;"Hey, everyone. Simba Khadder here of the MLOps weekly podcast, and today I'm speaking with Piero Molino. Piero is the CEO and co-founder of Predibase, a company that's redefining machine learning tooling with a declarative approach. He previously worked as a research scientist, exploring ML and NLP at Yahoo, IBM Watson, Geometric Intelligence, Uber, where he was actually a founding member of the Uber AI organization, and Stanford. He's the author of Ludwig, a Linux Foundation-backed open-source declarative deep learning framework with more than 8,500 stars. Piero, great to have you here today."
1;Piero Molino;00:00:43.240;00:00:46.980;00:00:03.740;"Thank you very much for having me, Simba. I really appreciate the time and the opportunity."
2;Simba Khadder;00:00:48.540;00:00:57.230;00:00:08.690;"I'd love to just jump in. I give a quick intro on you, but I'd love to hear in your own words. Tell me a bit about your journey to get to Predibase and building with Wix."
3;Piero Molino;00:00:57.760;00:01:22.620;00:00:24.860;"I will try to keep it short because it's actually pretty long, but I don't want to bore people with my own story. But I started by working on open domain question-answering. That was my research when I was doing the PhD. Then I worked at a bunch of companies, large ones like Yahoo and IBM Watson, where I was actually doing... Exactly what I was doing my research on was also the same thing that I was doing at IBM Watson."
4;Piero Molino;00:01:23.090;00:01:55.540;00:00:32.450;"But then I felt the urge to work at a smaller company and to work shoulder-to-shoulder with people where my decisions were really impactful for the company. I joined a startup that was called Geometric Intelligence, founded by a bunch of really nice people like Gary Marcus, Zoubin Gharamani, Ken Stanley, Jeff Clune and Noah Goodman. Because they're really well known in the machine learning space and they have a lot of experience, I wanted to work with them to learn a lot. That was my main intent when I started working in the company."
5;Piero Molino;00:01:56.060;00:02:18.610;00:00:22.550;"The company was acquired by Uber and so that's where I actually started working on Ludwig, which is the open-source foundation behind Predibase. The reason why I was working on that is that when I was at Uber, I was doing both research and application, so many different domains and many different actual machine learning tasks and products that Uber was adding machine learning capabilities to."
6;Piero Molino;00:02:19.350;00:02:33.320;00:00:13.970;"One of it was dialogue system for Uber drivers. Another one was a customer support model called Kota. Another one was the recommender system of Uber Eats, where I added a few additional capabilities. Another one was a fraud prediction model."
7;Piero Molino;00:02:34.060;00:02:51.860;00:00:17.800;"By working on all these different projects, I saw that there were a lot of things in common among these projects. I could build something like a tool for myself for making it much easier to work on the next project without reinventing the wheel from scratch."
8;Piero Molino;00:02:53.190;00:03:18.950;00:00:25.760;"That was the motivation for building Ludwig, which basically is a tool that creates an abstraction over the building actually of the machine learning pipeline by just requiring configuration file from the user, similar to what Terraform does for infrastructure. It's a declarative configuration where you can say, ""These are my inputs, these are my outputs, and these are the models that I want to use in the training parameters,"" for instance, and it builds the model for you."
9;Piero Molino;00:03:19.460;00:03:59.360;00:00:39.900;"This abstraction is at the core of what I'm building now at Predibase because this declarative abstraction is what we use for making it possible to more users actually to build machine learning models. We're building a bunch of capabilities around it, including capabilities of connecting with data, capabilities of managing the iteration of our models, capabilities of deployment, and capabilities of running these things at a large scale without having to care about the infrastructure to make this technology more accessible to organizations and more people within organizations, both engineers and scientists."
10;Piero Molino;00:04:00.210;00:04:34.660;00:00:34.450;"Also, I love that you mentioned Terraform. Actually, our name Featureforms comes from Terraform. I definitely think that the declarative approach to have a model is the right one. A lot of people, I imagine, associate with AutoML. It's because I think there was maybe in a previous iteration, I think it had more to do with it. It's obviously evolved and improved over time. I'd love to, if you could touch on that, is Ludwig an AutoML product? Is it not? When did that change happen? Did that change happen? I'd love to learn more."
11;Piero Molino;00:04:34.660;00:05:03.240;00:00:28.580;"Yeah. Actually, it's very interesting that at the beginning, I was not the one who used the term AutoML to describe it, but actually, when people picked on it, there were some videos on YouTube and some articles written by other people who defined it as an AutoML tool, but I was not the one starting it, I guess. The reason is that I think there's a substantial difference in the very basic approach behind it, although we added AutoML capabilities to Ludwig."
12;Piero Molino;00:05:03.310;00:05:45.820;00:00:42.510;"The main difference is that Ludwig starts as a mechanism for defining a declarative configuration for describing your own models. At the very beginning, there was no automation of defining what the model is. You had to define it in a simpler way for the configuration, but it was still something that the user had to do. The fact that there are still a lot of defaults make it feel like it's an AutoML tool, but there was no intelligence in defining those defaults beyond me picking values that I believe are working from papers, for instance."
13;Piero Molino;00:05:46.330;00:06:12.330;00:00:26.000;"To give a concrete example of this, if you specify that you have a text classification task, and you specify when input is text and when output is category, that's all you need to specify in Ludwig to make it work. What happens is it chooses the default model, which is like a CNN for text, because it's a really lightweight one compared to RNN transformers, and uses default cross entropy as the loss."
14;Piero Molino;00:06:12.950;00:06:28.930;00:00:16.170;"In the end, it trains like a really competent model to begin with, but there's no anything smart about it. It's just that's the default. The user can go there and says, ""Well, I want to use an RNN or a transformer instead of the CNN as the encoder for the text."""
15;Piero Molino;00:06:29.780;00:06:41.140;00:00:11.360;"The AutoML tool, what it actually does is it tries a bunch of different things for you, encoding some intelligence into this choice of what models to try, and then picks the best one."
16;Piero Molino;00:06:41.810;00:07:18.680;00:00:36.870;"Later on in Ludwig, we added... So this was at the beginning of Ludwig. Later on, we added additional capabilities, one around upper parameter optimization. You could say, for instance, ""I want to..."" Still declaratively, which means you can say, ""I want to try a CNN and an LSTM transformer for this task, and I want to try this learning rates within the range of 0.001 to 0.0001."" The process looks like an AutoML process because you try a bunch of different things and then they are stack ranked according to the performance. But still, the choice is the users when they're defining the ranges of parameters that they want to choose."
17;Piero Molino;00:07:19.270;00:07:53.050;00:00:33.780;"Then finally, more recently, I think it was already a year-and-a-half ago, something around that, we added some AutoML capabilities where you can go in Ludwig and you have an AutoML sub package, submodel, really, and you can say, ""Given this data set, suggest me a configuration."" But there is some smartness there because we tried many different configurations and we identified a bunch of configurations that work in many different scenarios for some specific tasks. Now we also have these capabilities."
18;Piero Molino;00:07:53.620;00:08:19.250;00:00:25.630;"But the core of it is that you have a configuration and you can change it and modify it the way you want and you can iterate over it, while AutoML is still a one-shot process where you have a data set and you get the model out and you have no levers, really. Nothing that you can do in the process once you get the model out. That's a fundamental difference in the spirit of it, really."
19;Simba Khadder;00:08:20.280;00:08:53.620;00:00:33.340;"So Ludwig does a lot. It sounds like it's almost in some ways competitive to PyTorch, but also being competitive to some of the AutoML frameworks. What would you say... I guess two questions. One is, is your user typically any data scientist doing machine learning? Is there a specific subcategory of data scientists who use you more? And I guess the follow on would be, why [inaudible 00:08:45]? Why would they choose to use Ludwig over using PyTorch directly or just throwing it into DataRobot or [inaudible 00:08:53]?"
20;Piero Molino;00:08:54.280;00:09:18.060;00:00:23.780;"Right. I think there's two souls, if you want, of the tool that also reflected by their users, the two kinds of main users if you want. And I would say, by the way, Ludwig is built on top of PyTorch, so basically every single Ludwig model is a PyTorch model. And so it's not really a replacement for PyTorch. It's like a higher-level abstraction that makes it easy to do PyTorch."
21;Piero Molino;00:09:18.890;00:10:03.220;00:00:44.330;"If you want, on one hand you have, again, the more... Let's take it this way. On one hand, you have the more detailed tools, low level tools that machine learning engineers use, like PyTorch, TensorFlow, [inaudible 00:09:35], and on the other hand, you have the AutoML tools. We believe that the declarative obstruction and Ludwig as an example of that declarative obstruction is a happy middle where you have the degree of control or close to the degree of control of the low level machine learning framework and the simplicity of use of an AutoML tool without sacrificing the actionability and the fact that you can change any single parameter."
22;Piero Molino;00:10:03.920;00:10:26.510;00:00:22.590;"As a consequence, users that are using Ludwig right now and are targets for Ludwig really are both more experienced users that could build these models themselves, but it will require them time, and so by using Ludwig, they are saving a lot of time, or users that maybe are the first categories, like data scientists and experienced machine learning engineers."
23;Piero Molino;00:10:27.560;00:11:00.570;00:00:33.010;"The second category is people that may be may not know how to build, for instance, deep learning model with PyTorch for a specific task, but the configuration system makes it very easy for them to get a competent model out of the box, and so those people are the people that would be more drawn to an AutoML tool, but at the same time, don't adopt them because they create an artificial ceiling. They want to grow with the tool and want to have the possibility to change the parameters and basically iterate over the models and improve them."
24;Piero Molino;00:11:00.960;00:11:25.790;00:00:24.830;"These people are more engineers. They want to get something into their application, for instance, in the building, and they want to add the machine learning capability. But at the same time, they don't want to be locked in into an AutoML solution, or they don't want to just cross their fingers and say, ""Well, if I'm going to get a good model out of the box, great. Otherwise, I don't know what to do."" They want to feel like they can influence the process of how they get the model themselves."
25;Simba Khadder;00:11:26.640;00:11:36.690;00:00:10.050;"I like the comparison of the happy middle. How would you define the category? Is there a category that Ludwig fits in or is it its own thing?"
26;Piero Molino;00:11:37.990;00:11:59.800;00:00:21.810;"We are describing it as a declarative machine learning tool because of the configuration-based approach. I think it's again, it's slightly different from both the low-level machine learning frameworks and the AutoML tools. But I think all of these things live in the same space to a certain extent, which is machine learning tooling, really, machine learning platforms or machine learning tooling."
27;Simba Khadder;00:12:00.580;00:12:16.720;00:00:16.140;"Where do you think it fits into maybe the broader MLOps ecosystem when you think of things like [inaudible 00:12:06], Comet, which I assume there's probably more tie-in all the way from feature stores, observability platforms? How does it all fit together in your head?"
28;Piero Molino;00:12:17.240;00:12:42.560;00:00:25.320;"This is maybe slightly different from Ludwig and Predibase, if you want. For Ludwig, for instance, we have plug-ins for Comet with some biases, MLflow for tracking experiments when users run them through Ludwig automatically. So just add dash-dash Comet, for instance, and the experiment that you're running in the training or the prediction that you're running is tracked on the specific tool that you specified."
29;Piero Molino;00:12:43.140;00:13:05.490;00:00:22.350;"With respect to object stores, there's nothing explicit in Ludwig, but I think there's a very, if you want, clean interface between object store and Ludwig, meaning that literally the output of the object store can be the input to the training of Ludwig, and then the output of Ludwig can be written back into a data source that then the object store can read from."
30;Piero Molino;00:13:06.780;00:13:46.920;00:00:40.140;"I would say the only caveat there is that Ludwig also does some data preprocessing. The way we define it really is anything that is common among multiple machine learning tasks that is specific to a data type, we try to incorporate it. For instance, for text, tokenization, shortening of the text up to a certain specific length, cleaning of text by, for instance, lower casing or not. These capabilities are there in Ludwig. The same is true for images and other data types like normalisation for numerical values and things like that."
31;Piero Molino;00:13:47.410;00:14:13.430;00:00:26.020;"What is not there in Ludwig is something that is bespoke for the data set, which could be, for instance, having a notion of rolling up a table for deriving features or for aggregating them or things like that, that is not in the domain of Ludwig. Feature stores are the best solution that we know right now for doing those things. Ludwig can take the output of that and train them also."
32;Piero Molino;00:14:13.990;00:14:55.090;00:00:41.100;"For Predibase, I would say we are trying to make the experience of the users really cohesive, if you want. We still don't focus on the feature store part, but all the other aspects of model management, model deployment, and infrastructure, we take care of all of them. The reason is that we believe that through that integration, we can provide a much better experience. Many organizations, what they do, they take different tools, maybe best-in-class tools for all of these things, and they put them together in a way that maybe if you want... Let me rephrase this thing."
33;Piero Molino;00:14:55.090;00:15:30.270;00:00:35.180;"I would say many organization pick best-in-class tools and tries to put them together into a way that is cohesive and there's merit to this approach. But what we're trying to do is we're trying to make it so that they don't even have to think about putting these tools together. It's a higher level of obstruction that we are trying to provide to users. The reason is if you have a system that knows exactly, like a deployment system that knows exactly what is the specific models that are going to be deployed, it can be much simpler than a tool that needs to support every single model format."
34;Piero Molino;00:15:30.310;00:16:02.350;00:00:32.040;"Same is true for experiment tracking. If you know exactly what is the format of the output of the training process, you don't need to support TensorFlow, PyTorch, or any other mechanism for training models that can write metrics in a super generic way that is maybe not supported already. Because of that, we can make decisions that make each single component that we are building substantially simpler than what best-in-class solution that supports everything is, but at the same time delivers the same amount of value for the customer since they're adopting the platform."
35;Simba Khadder;00:16:03.400;00:16:48.690;00:00:45.290;"Got it. So today, it seems like there is simultaneously a lot of, let's call it MLOps platforms, Predibase and that kind of... It's in that realm where it's going across a few of the maybe proto-categories of MLOps. Then there's obviously the, let's call them category players, like observability companies, there's serving companies, et cetera. What do you think the future is there? Do you think it mostly will continue to split up and be like many different categories that people will meet together? Do you think they'll mostly be platforms? I assume it'll likely be a mix, but I'm wondering, do you think it's going to lean heavily towards platform-based or heavily towards stitched together best-in-class vendor-based?"
36;Piero Molino;00:16:49.640;00:17:23.589;00:00:33.949;"Honestly, I think that machine learning, we're already seeing it, honestly, is growing so much as a field and so much as an industry category, if you want, that I believe there will be space for all of these solutions because they target different customers, really, and what they are capable of building in-house, what they are capable of buying out, and what they find the highest value building, assembling, or using."
37;Piero Molino;00:17:24.369;00:18:03.740;00:00:39.370;"I imagine a world where customers that are not tech companies may not want to build anything in-house and not even stitching things in-house. Customers attracted to companies that need to have a deeper degree of customization and control over what they're building. They may be building something in-house and stitching something together. And as us scalers, we'll be building everything in-house because even like a 0.0001% improvement in efficiency, either accuracy or speed or performance or anything, means millions and millions of dollars for them, so they have a reason for doing that."
38;Piero Molino;00:18:03.740;00:18:19.370;00:00:15.630;"I think you're going to see this full spectrum. I think we're going to see different classes of companies adopting different solutions. I don't think it will be one that will overcome all the others. That's the way I feel about it."
39;Simba Khadder;00:18:19.940;00:18:24.580;00:00:04.640;"Obviously, one of the hot topics today is, let's call it, LMs and foundational models."
40;Piero Molino;00:18:24.640;00:18:25.130;00:00:00.488;"Right."
41;Simba Khadder;00:18:25.190;00:18:50.100;00:00:24.910;"Where do you think the world is going? Is your ML dead? Is it over? Is everything going to be a founda... Have we figured it out? It's all foundational models? Is it going to be a mix? What's your sense of how... And also, I guess another part I'd love to have you expand on is, are these two separate paradigms? There will be traditional ML workflows and there will be, let's call it, foundational ML workflows, or do you think there's going to be some mixing?"
42;Piero Molino;00:18:50.700;00:19:36.920;00:00:46.220;"That's a very interesting question, in particular, the second one. Let me start from that one, I would say, and then try to go back to the first one. On the second one, I think that there is mixing. Also, we are thinking about it at Predibase, and we're starting to put out some material about it, some webinars and some documentation about the way we're thinking about it, is that now we have function that in many cases is capable of producing the outputs that a machine learning model was required to produce up until recently. That is great because it means that the barrier of entry is substantially lower."
43;Piero Molino;00:19:37.020;00:20:02.990;00:00:25.970;"At the same time, that function may not be the best one from many different perspectives for solving the task. It's a function that can do many different things. Maybe that specific thing that you wanted to do may not be the best one at doing that specific thing, may not be the fastest one at doing that specific thing, may not be the most cost-efficient one at doing that specific thing."
44;Piero Molino;00:20:03.470;00:20:38.310;00:00:34.840;"In my mind, there will be a coexistence of large language models, foundation models in general, and more, if you want, traditional machine learning models because of the fact that I can imagine that users will approach solving their problems using an LLM, see that it is feasible and there's value in doing it, and then finding ways to make it cheaper, faster, and cost-effective, really, and that will be probably building a bespoke model for the specific tasks that they care about."
45;Simba Khadder;00:20:38.440;00:21:00.670;00:00:22.230;"And in that same light, is the same thing true of AutoML? You would maybe use an LLM as a generic, almost perfect AutoML-type thing, but then you might use an AutoML solution or tool to try to achieve similar performance characteristics for a much lower price, maybe faster. Is that the right way to think about it?"
46;Piero Molino;00:21:01.080;00:21:15.950;00:00:14.870;"Yeah, I think that makes sense. It's a matter of what is, from a performance perspective, good enough and what is good enough from, again, all the other considerations like in cost, speed, and all of that."
47;Piero Molino;00:21:16.800;00:21:42.300;00:00:25.500;"There will be some cases where the LLM may be good enough from all these points of view. And there will be cases where it will be not. AutoML has the same promise, if you want, that I give you some data and there's a model coming back from it, and that the model is good enough for your task."
48;Piero Molino;00:21:42.360;00:22:00.150;00:00:17.790;"The problem is when you get out of the happy path when it is not good enough. The same thing is true for data learning in my mind. When it is not good enough, what are you going to do? Then all the other things that we've been working on for a while will keep on being relevant in all these cases."
49;Simba Khadder;00:22:00.520;00:22:34.430;00:00:33.910;"I'm curious, just because I know you have some research background in question-answering and other stuff in that realm. You're probably very familiar with transformers, embeddings, that space in that problem space. We use to my last company, the recommendation system, we used to... We have lots of multi-model stuff. We'd create embeddings on images, on users, on pretty much anything. We'd feed them into further models that have very specific tasks, whether it be ranking, whatever it be. It's a lot of predicting something to subscribe, et cetera."
50;Simba Khadder;00:22:34.500;00:23:04.610;00:00:30.110;"It's interesting to see vector databases finding this new home and this new LLM landscape because it's almost like treating LLMs as this super transformer. I guess that makes me wonder if we're going to start using LLMs as same way we've used transformers historically, where it's like, ""Hey, we're not using Bard, we're using GPT-7 now because it's 100 times better."" Do you think that makes sense? Do you think you feel like the world is moving that direction, or do you think that's not what the future looks like?"
51;Piero Molino;00:23:06.040;00:23:32.230;00:00:26.190;"Yeah. So I think in particular, from a question-answering perspective, and again, recommender systems in this sense are relatively similar to that in my mind. You can use an NLM for embedding stuff. I think the value in it is slightly different than what it was before because before you would embed something and then retrieve it and the retrieval was the task in and itself."
52;Piero Molino;00:23:32.230;00:24:12.820;00:00:40.590;"I think now you can do more interesting things than that. An example is you can index something in a vector store and then when you retrieve, what you retrieve is not the output, what you retrieve is what goes into an input to a further step in the processing of that information through the LLM. You may want to summarize it, you may want to add references, you may want to use the supporting evidence for the answers that you are giving. You may use it as samples for doing few short learning, really, and then actually it's just examples for different tasks."
53;Piero Molino;00:24:13.360;00:24:45.390;00:00:32.030;"There's much more that you can do in the paradigm of, ""I'm using LLM for being the controller of the process that I'm doing."" There are some examples like that. The things that people are building with Long Chain are super cool. There's this startup called Fixy that is using LLM as a dispatcher really towards other functions, which could be LLMs themselves, could be something else, and integrate the capabilities or those other models into the interaction with the user. It opens up more possibilities than just when they were before."
54;Simba Khadder;00:24:46.260;00:24:50.390;00:00:04.130;"Totally. Yeah, it makes sense. Fixy is actually... We share a lead investor of them inside us."
55;Piero Molino;00:24:50.550;00:24:50.880;00:00:00.330;"Oh, nice."
56;Simba Khadder;00:24:50.880;00:25:14.150;00:00:23.270;"It's been cool to see them be so successful. I think you're totally right. I think embedding... We've already been seeing them being used essentially as features. It's almost like an interesting point because it's like... What I would call maybe a traditional feature would be, let's Z score this, or let's do this aggregation. It's a SQL query, essentially, but it's what it looks like."
57;Simba Khadder;00:25:14.680;00:25:31.480;00:00:16.800;"But nowadays, those, let's call them transformation steps, are actually transformers or even like LLMs. Those generate outputs and those outputs are features. In this case, the feature happens to be a vector. I think that that's going to become really interesting."
58;Simba Khadder;00:25:31.780;00:25:54.820;00:00:23.040;"I think it's a bit untapped still because I think it's what goes from taking, I guess, what people call a fat client, where it's like, I think a lot of the LLM or companies I see in the application space there, it's like what's the look very similar to me. It makes sense because they're all using the same API and the API is text or prompts, I guess."
59;Simba Khadder;00:25:55.090;00:26:21.650;00:00:26.560;"The problem with prompts is... The great thing about prompts is my grandma can use them. The hard thing about prompts is that that's about as far as you can get. You just have to start trying to come up with crazy hacks to try to make these things work better. Anyway, I think that's where things get interesting to me, is seeing embedding and these intermediaries and starting to build logic on top of those to build more interesting application."
60;Piero Molino;00:26:22.390;00:26:40.600;00:00:18.210;"Yeah. Again, I agree with that. And also there is this interesting take that I've seen some people agreeing with regarding the fact that it is true, anybody can now use this interface because prompting is something that looks like language and can be natural for people to do that."
61;Piero Molino;00:26:40.600;00:27:03.650;00:00:23.050;"But at the same time, if you look at it from the point of view of a developer, it's a little bit like waving a magic wand in the air and hoping that something comes out. We have some affordances through language, but we don't really know the space of what is possible and we don't really know why and if some of the changes that we make to a prompt should or should not work."
62;Piero Molino;00:27:03.650;00:27:22.440;00:00:18.790;"We may have some intuition, some human language intuition, but they may not be actually true. Maybe a prompt that is slightly less grammatical may be a better prompt for achieving a specific goal. We actually didn't know that. This trial and error is really a little bit of a black hat."
63;Piero Molino;00:27:23.410;00:27:42.920;00:00:19.510;"If you think from the perspective of someone who has been developing machine learning systems through programming languages, where you have a mental model of what the compiler or the interpreter will do and you know exactly what you need to change to make that happen, it's a little bit disconcerning for people who have been building things that way."
64;Simba Khadder;00:27:43.020;00:28:20.180;00:00:37.160;"It reminds me. There's this fact I learned, which is, crabs, the animal, have been evolutionarily created many different times from many different places. There's the joke of it's the most effective or efficient. It's like the perfect... Evolution has decided that this thing is a global minima. We keep ending up here. I have the same joke about SQL, where it's like we keep moving away from it, and in the end, we always seem to come back to SQL. I joke about maybe one day we'll be prompting our LLMs in SQL again. We'll have a SQL dialect for LLMs."
65;Piero Molino;00:28:20.180;00:28:56.370;00:00:36.190;"There's already one. It's called like... We are doing something like that ourselves because we have this people programming predictive language in Predibase, and there's this... Let me search it up because I want to give you a good answer about it. I think it's called LLMQL, if I am correct, or LMQL. I want to be precise about it. Yeah, so LMQL. There is this other research team actually that is building this thing called LMQL, and there's a paper about it. We are doing this covering SQL yet once more for quitting large language models. It's interesting."
66;Piero Molino;00:28:56.370;00:29:29.960;00:00:33.590;"I also strongly believe that SQL declarative interfaces like that are a global medium, at the very least a local one, that we end up there more and more time. I remember when I was at Yahoo, for instance, it's a little bit of a side, but Yahoo was the company open-sourcing Hadoop at the beginning, and so it had a lot of legacy. When I interned there, I was writing Java code for running Hadoop jobs on Hadoop 0 dot-something when the whole industry was at Hadoop 2 dot-something just because Yahoo had a lot of legacy Hadoop stuff."
67;Piero Molino;00:29:30.460;00:29:53.170;00:00:22.710;"I was writing basically select and where clauses but with a very verbose way, really the heart of the bug and all of that. Then there were added SQL parses into [inaudible 00:29:45] jobs that made it substantially easier. We really discover the basic things sometimes over and over again. I agree with you."
68;Simba Khadder;00:29:53.660;00:30:13.800;00:00:20.140;"Exactly. Yeah. Then when Kiv comes out and it's like, ""Yeah, maybe one day after the AI apocalypse, there will be just crabs and SQL. There will be nothing else. That's it. That's the best we could come up with."" Piero, it's been great to have you on. I really appreciate your time and your takes and your insights. I hope to maybe have you on again."
69;Piero Molino;00:30:13.800;00:30:22.340;00:00:08.540;"Yeah, looking forward to it. I had a good time. It was fun tracking. Thank you for spending time with me."
